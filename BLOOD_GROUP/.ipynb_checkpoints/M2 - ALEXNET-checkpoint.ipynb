{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6a08101",
   "metadata": {},
   "source": [
    "## ALEXNET ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69df34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7239e0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv2D, Conv3D, DepthwiseConv2D, SeparableConv2D, Conv3DTranspose\n",
    "from keras.layers import Flatten, MaxPool2D, AvgPool2D, GlobalAvgPool2D, UpSampling2D, BatchNormalization\n",
    "from keras.layers import Concatenate, Add, Dropout, ReLU, Lambda, Activation, LeakyReLU, PReLU\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f92c584",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'DATASET/TRAIN'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m      3\u001b[0m train\u001b[38;5;241m=\u001b[39mImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m,shear_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,zoom_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,horizontal_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,validation_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m train_data\u001b[38;5;241m=\u001b[39mtrain\u001b[38;5;241m.\u001b[39mflow_from_directory(directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATASET/TRAIN\u001b[39m\u001b[38;5;124m'\u001b[39m,target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m224\u001b[39m),\n\u001b[0;32m      5\u001b[0m                                      batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\preprocessing\\image.py:1648\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[0;32m   1563\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1564\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1579\u001b[0m ):\n\u001b[0;32m   1580\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[0;32m   1581\u001b[0m \n\u001b[0;32m   1582\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1646\u001b[0m \u001b[38;5;124;03m            and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DirectoryIterator(\n\u001b[0;32m   1649\u001b[0m         directory,\n\u001b[0;32m   1650\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1651\u001b[0m         target_size\u001b[38;5;241m=\u001b[39mtarget_size,\n\u001b[0;32m   1652\u001b[0m         color_mode\u001b[38;5;241m=\u001b[39mcolor_mode,\n\u001b[0;32m   1653\u001b[0m         keep_aspect_ratio\u001b[38;5;241m=\u001b[39mkeep_aspect_ratio,\n\u001b[0;32m   1654\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[0;32m   1655\u001b[0m         class_mode\u001b[38;5;241m=\u001b[39mclass_mode,\n\u001b[0;32m   1656\u001b[0m         data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format,\n\u001b[0;32m   1657\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1658\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m   1659\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m   1660\u001b[0m         save_to_dir\u001b[38;5;241m=\u001b[39msave_to_dir,\n\u001b[0;32m   1661\u001b[0m         save_prefix\u001b[38;5;241m=\u001b[39msave_prefix,\n\u001b[0;32m   1662\u001b[0m         save_format\u001b[38;5;241m=\u001b[39msave_format,\n\u001b[0;32m   1663\u001b[0m         follow_links\u001b[38;5;241m=\u001b[39mfollow_links,\n\u001b[0;32m   1664\u001b[0m         subset\u001b[38;5;241m=\u001b[39msubset,\n\u001b[0;32m   1665\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[0;32m   1666\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   1667\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\preprocessing\\image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m    562\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(directory)):\n\u001b[0;32m    564\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    565\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'DATASET/TRAIN'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,validation_split = 0.2)\n",
    "train_data=train.flow_from_directory(directory = 'DATASET/TRAIN',target_size=(224,224),\n",
    "                                     batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355dd2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=ImageDataGenerator(rescale=1./255)\n",
    "test_data=test.flow_from_directory(directory = 'DATASET/TEST',target_size=(224,224),\n",
    "                                   batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2310570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet(input_shape, n_classes):\n",
    "  input = Input(input_shape)\n",
    "  \n",
    "  # actually batch normalization didn't exist back then\n",
    "  # they used LRN (Local Response Normalization) for regularization\n",
    "  x = Conv2D(96, 11, strides=4, padding='same', activation='relu')(input)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = MaxPool2D(3, strides=2)(x)\n",
    "  \n",
    "  x = Conv2D(256, 5, padding='same', activation='relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = MaxPool2D(3, strides=2)(x)\n",
    "  \n",
    "  x = Conv2D(384, 3, strides=1, padding='same', activation='relu')(x)\n",
    "  \n",
    "  x = Conv2D(384, 3, strides=1, padding='same', activation='relu')(x)\n",
    "  \n",
    "  x = Conv2D(256, 3, strides=1, padding='same', activation='relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = MaxPool2D(3, strides=2)(x)\n",
    "  \n",
    "  x = Flatten()(x)\n",
    "  x = Dense(4096, activation='relu')(x)\n",
    "  x = Dense(4096, activation='relu')(x)\n",
    "  \n",
    "  output = Dense(n_classes, activation='softmax')(x)\n",
    "  \n",
    "  model = Model(input, output)\n",
    "  model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy',tensorflow.keras.metrics.Precision()])\n",
    "  return model\n",
    "\n",
    "input_shape = 224, 224, 3\n",
    "n_classes = 14\n",
    "\n",
    "K.clear_session()\n",
    "model = alexnet(input_shape, n_classes)\n",
    "model.summary()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef429a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"ALEXNET.h5\"\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "M = ModelCheckpoint(model_path, monitor='accuracy', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0c46be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3935 - accuracy: 0.2292 - precision: 0.0000e+00\n",
      "Epoch 1: accuracy improved from -inf to 0.22917, saving model to GOOGLE.h5\n",
      "3/3 [==============================] - 24s 5s/step - loss: 1.3935 - accuracy: 0.2292 - precision: 0.0000e+00 - val_loss: 1.3897 - val_accuracy: 0.2604 - val_precision: 0.0000e+00\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3846 - accuracy: 0.2708 - precision: 0.0000e+00\n",
      "Epoch 2: accuracy improved from 0.22917 to 0.27083, saving model to GOOGLE.h5\n",
      "3/3 [==============================] - 19s 7s/step - loss: 1.3846 - accuracy: 0.2708 - precision: 0.0000e+00 - val_loss: 1.3840 - val_accuracy: 0.2604 - val_precision: 0.0000e+00\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3989 - accuracy: 0.1667 - precision: 0.0000e+00\n",
      "Epoch 3: accuracy did not improve from 0.27083\n",
      "3/3 [==============================] - 19s 7s/step - loss: 1.3989 - accuracy: 0.1667 - precision: 0.0000e+00 - val_loss: 1.3835 - val_accuracy: 0.2708 - val_precision: 0.0000e+00\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3890 - accuracy: 0.1667 - precision: 0.0000e+00\n",
      "Epoch 4: accuracy did not improve from 0.27083\n",
      "3/3 [==============================] - 20s 7s/step - loss: 1.3890 - accuracy: 0.1667 - precision: 0.0000e+00 - val_loss: 1.3848 - val_accuracy: 0.3021 - val_precision: 0.0000e+00\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3848 - accuracy: 0.3229 - precision: 0.0000e+00\n",
      "Epoch 5: accuracy improved from 0.27083 to 0.32292, saving model to GOOGLE.h5\n",
      "3/3 [==============================] - 21s 7s/step - loss: 1.3848 - accuracy: 0.3229 - precision: 0.0000e+00 - val_loss: 1.3909 - val_accuracy: 0.1458 - val_precision: 0.0000e+00\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3880 - accuracy: 0.2500 - precision: 0.0000e+00\n",
      "Epoch 6: accuracy did not improve from 0.32292\n",
      "3/3 [==============================] - 20s 6s/step - loss: 1.3880 - accuracy: 0.2500 - precision: 0.0000e+00 - val_loss: 1.3821 - val_accuracy: 0.3125 - val_precision: 0.0000e+00\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3771 - accuracy: 0.2917 - precision: 0.0000e+00\n",
      "Epoch 7: accuracy did not improve from 0.32292\n",
      "3/3 [==============================] - 22s 7s/step - loss: 1.3771 - accuracy: 0.2917 - precision: 0.0000e+00 - val_loss: 1.3841 - val_accuracy: 0.2812 - val_precision: 0.0000e+00\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.4070 - accuracy: 0.2396 - precision: 0.0000e+00\n",
      "Epoch 8: accuracy did not improve from 0.32292\n",
      "3/3 [==============================] - 22s 7s/step - loss: 1.4070 - accuracy: 0.2396 - precision: 0.0000e+00 - val_loss: 1.3917 - val_accuracy: 0.1354 - val_precision: 0.0000e+00\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3861 - accuracy: 0.2083 - precision: 0.0000e+00\n",
      "Epoch 9: accuracy did not improve from 0.32292\n",
      "3/3 [==============================] - 18s 7s/step - loss: 1.3861 - accuracy: 0.2083 - precision: 0.0000e+00 - val_loss: 1.3878 - val_accuracy: 0.1979 - val_precision: 0.0000e+00\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3882 - accuracy: 0.2396 - precision: 0.0000e+00\n",
      "Epoch 10: accuracy did not improve from 0.32292\n",
      "3/3 [==============================] - 19s 7s/step - loss: 1.3882 - accuracy: 0.2396 - precision: 0.0000e+00 - val_loss: 1.3863 - val_accuracy: 0.2708 - val_precision: 0.0000e+00\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3889 - accuracy: 0.1979 - precision: 0.0000e+00\n",
      "Epoch 11: accuracy did not improve from 0.32292\n",
      "3/3 [==============================] - 18s 6s/step - loss: 1.3889 - accuracy: 0.1979 - precision: 0.0000e+00 - val_loss: 1.3890 - val_accuracy: 0.2188 - val_precision: 0.0000e+00\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3855 - accuracy: 0.2812 - precision: 0.0000e+00\n",
      "Epoch 12: accuracy did not improve from 0.32292\n",
      "3/3 [==============================] - 18s 6s/step - loss: 1.3855 - accuracy: 0.2812 - precision: 0.0000e+00 - val_loss: 1.3859 - val_accuracy: 0.2292 - val_precision: 0.0000e+00\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3862 - accuracy: 0.2500 - precision: 0.0000e+00\n",
      "Epoch 13: accuracy did not improve from 0.32292\n",
      "3/3 [==============================] - 19s 6s/step - loss: 1.3862 - accuracy: 0.2500 - precision: 0.0000e+00 - val_loss: 1.3841 - val_accuracy: 0.3021 - val_precision: 0.0000e+00\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3842 - accuracy: 0.3438 - precision: 0.0000e+00\n",
      "Epoch 14: accuracy improved from 0.32292 to 0.34375, saving model to GOOGLE.h5\n",
      "3/3 [==============================] - 20s 7s/step - loss: 1.3842 - accuracy: 0.3438 - precision: 0.0000e+00 - val_loss: 1.3872 - val_accuracy: 0.2500 - val_precision: 0.0000e+00\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3841 - accuracy: 0.3021 - precision: 0.0000e+00\n",
      "Epoch 15: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 19s 7s/step - loss: 1.3841 - accuracy: 0.3021 - precision: 0.0000e+00 - val_loss: 1.3873 - val_accuracy: 0.2604 - val_precision: 0.0000e+00\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3856 - accuracy: 0.2917 - precision: 0.0000e+00\n",
      "Epoch 16: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 19s 7s/step - loss: 1.3856 - accuracy: 0.2917 - precision: 0.0000e+00 - val_loss: 1.3889 - val_accuracy: 0.2500 - val_precision: 0.0000e+00\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3955 - accuracy: 0.2083 - precision: 0.0000e+00\n",
      "Epoch 17: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 20s 7s/step - loss: 1.3955 - accuracy: 0.2083 - precision: 0.0000e+00 - val_loss: 1.3820 - val_accuracy: 0.2917 - val_precision: 0.0000e+00\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3943 - accuracy: 0.1875 - precision: 0.0000e+00\n",
      "Epoch 18: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 18s 7s/step - loss: 1.3943 - accuracy: 0.1875 - precision: 0.0000e+00 - val_loss: 1.3894 - val_accuracy: 0.2188 - val_precision: 0.0000e+00\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3858 - accuracy: 0.2708 - precision: 0.0000e+00\n",
      "Epoch 19: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 18s 6s/step - loss: 1.3858 - accuracy: 0.2708 - precision: 0.0000e+00 - val_loss: 1.3819 - val_accuracy: 0.3021 - val_precision: 0.0000e+00\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3860 - accuracy: 0.2604 - precision: 0.0000e+00\n",
      "Epoch 20: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 20s 7s/step - loss: 1.3860 - accuracy: 0.2604 - precision: 0.0000e+00 - val_loss: 1.3841 - val_accuracy: 0.2812 - val_precision: 0.0000e+00\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3847 - accuracy: 0.2812 - precision: 0.0000e+00\n",
      "Epoch 21: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 20s 6s/step - loss: 1.3847 - accuracy: 0.2812 - precision: 0.0000e+00 - val_loss: 1.3853 - val_accuracy: 0.2812 - val_precision: 0.0000e+00\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3907 - accuracy: 0.1979 - precision: 0.0000e+00\n",
      "Epoch 22: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 18s 6s/step - loss: 1.3907 - accuracy: 0.1979 - precision: 0.0000e+00 - val_loss: 1.3847 - val_accuracy: 0.2604 - val_precision: 0.0000e+00\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3846 - accuracy: 0.3021 - precision: 0.0000e+00\n",
      "Epoch 23: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 20s 7s/step - loss: 1.3846 - accuracy: 0.3021 - precision: 0.0000e+00 - val_loss: 1.3885 - val_accuracy: 0.2083 - val_precision: 0.0000e+00\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3878 - accuracy: 0.2188 - precision: 0.0000e+00\n",
      "Epoch 24: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 21s 7s/step - loss: 1.3878 - accuracy: 0.2188 - precision: 0.0000e+00 - val_loss: 1.3803 - val_accuracy: 0.2396 - val_precision: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3671 - accuracy: 0.3229 - precision: 0.6250    \n",
      "Epoch 25: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 19s 7s/step - loss: 1.3671 - accuracy: 0.3229 - precision: 0.6250 - val_loss: 1.3607 - val_accuracy: 0.2500 - val_precision: 0.0000e+00\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3814 - accuracy: 0.2604 - precision: 0.0000e+00\n",
      "Epoch 26: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 19s 7s/step - loss: 1.3814 - accuracy: 0.2604 - precision: 0.0000e+00 - val_loss: 1.3871 - val_accuracy: 0.2396 - val_precision: 0.0000e+00\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3880 - accuracy: 0.2083 - precision: 0.0000e+00\n",
      "Epoch 27: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 20s 7s/step - loss: 1.3880 - accuracy: 0.2083 - precision: 0.0000e+00 - val_loss: 1.3857 - val_accuracy: 0.2604 - val_precision: 0.0000e+00\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3860 - accuracy: 0.2500 - precision: 0.0000e+00\n",
      "Epoch 28: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 20s 7s/step - loss: 1.3860 - accuracy: 0.2500 - precision: 0.0000e+00 - val_loss: 1.3867 - val_accuracy: 0.2604 - val_precision: 0.0000e+00\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3864 - accuracy: 0.2083 - precision: 0.0000e+00\n",
      "Epoch 29: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 20s 7s/step - loss: 1.3864 - accuracy: 0.2083 - precision: 0.0000e+00 - val_loss: 1.3869 - val_accuracy: 0.2708 - val_precision: 0.0000e+00\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3868 - accuracy: 0.2292 - precision: 0.0000e+00\n",
      "Epoch 30: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 21s 7s/step - loss: 1.3868 - accuracy: 0.2292 - precision: 0.0000e+00 - val_loss: 1.3877 - val_accuracy: 0.1979 - val_precision: 0.0000e+00\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3857 - accuracy: 0.2917 - precision: 0.0000e+00\n",
      "Epoch 31: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 21s 7s/step - loss: 1.3857 - accuracy: 0.2917 - precision: 0.0000e+00 - val_loss: 1.3849 - val_accuracy: 0.2917 - val_precision: 0.0000e+00\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3868 - accuracy: 0.2604 - precision: 0.0000e+00\n",
      "Epoch 32: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 21s 7s/step - loss: 1.3868 - accuracy: 0.2604 - precision: 0.0000e+00 - val_loss: 1.3856 - val_accuracy: 0.3438 - val_precision: 0.0000e+00\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3881 - accuracy: 0.2125 - precision: 0.0000e+00\n",
      "Epoch 33: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 19s 6s/step - loss: 1.3881 - accuracy: 0.2125 - precision: 0.0000e+00 - val_loss: 1.3843 - val_accuracy: 0.3229 - val_precision: 0.0000e+00\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3857 - accuracy: 0.2625 - precision: 0.0000e+00\n",
      "Epoch 34: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 17s 7s/step - loss: 1.3857 - accuracy: 0.2625 - precision: 0.0000e+00 - val_loss: 1.3884 - val_accuracy: 0.2083 - val_precision: 0.0000e+00\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3872 - accuracy: 0.2812 - precision: 0.0000e+00\n",
      "Epoch 35: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 20s 6s/step - loss: 1.3872 - accuracy: 0.2812 - precision: 0.0000e+00 - val_loss: 1.3854 - val_accuracy: 0.2604 - val_precision: 0.0000e+00\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3866 - accuracy: 0.2396 - precision: 0.0000e+00\n",
      "Epoch 36: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 21s 7s/step - loss: 1.3866 - accuracy: 0.2396 - precision: 0.0000e+00 - val_loss: 1.3864 - val_accuracy: 0.2188 - val_precision: 0.0000e+00\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3877 - accuracy: 0.2188 - precision: 0.0000e+00\n",
      "Epoch 37: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 20s 7s/step - loss: 1.3877 - accuracy: 0.2188 - precision: 0.0000e+00 - val_loss: 1.3865 - val_accuracy: 0.2500 - val_precision: 0.0000e+00\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3880 - accuracy: 0.1979 - precision: 0.0000e+00\n",
      "Epoch 38: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 21s 7s/step - loss: 1.3880 - accuracy: 0.1979 - precision: 0.0000e+00 - val_loss: 1.3869 - val_accuracy: 0.2188 - val_precision: 0.0000e+00\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3859 - accuracy: 0.2292 - precision: 0.0000e+00\n",
      "Epoch 39: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 20s 7s/step - loss: 1.3859 - accuracy: 0.2292 - precision: 0.0000e+00 - val_loss: 1.3857 - val_accuracy: 0.2812 - val_precision: 0.0000e+00\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3864 - accuracy: 0.2812 - precision: 0.0000e+00\n",
      "Epoch 40: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 21s 7s/step - loss: 1.3864 - accuracy: 0.2812 - precision: 0.0000e+00 - val_loss: 1.3857 - val_accuracy: 0.3021 - val_precision: 0.0000e+00\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3866 - accuracy: 0.2396 - precision: 0.0000e+00\n",
      "Epoch 41: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 18s 6s/step - loss: 1.3866 - accuracy: 0.2396 - precision: 0.0000e+00 - val_loss: 1.3875 - val_accuracy: 0.2083 - val_precision: 0.0000e+00\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3868 - accuracy: 0.2604 - precision: 0.0000e+00\n",
      "Epoch 42: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 19s 6s/step - loss: 1.3868 - accuracy: 0.2604 - precision: 0.0000e+00 - val_loss: 1.3846 - val_accuracy: 0.3021 - val_precision: 0.0000e+00\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3865 - accuracy: 0.2604 - precision: 0.0000e+00\n",
      "Epoch 43: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 20s 7s/step - loss: 1.3865 - accuracy: 0.2604 - precision: 0.0000e+00 - val_loss: 1.3875 - val_accuracy: 0.1250 - val_precision: 0.0000e+00\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3851 - accuracy: 0.3125 - precision: 0.0000e+00\n",
      "Epoch 44: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 19s 6s/step - loss: 1.3851 - accuracy: 0.3125 - precision: 0.0000e+00 - val_loss: 1.3842 - val_accuracy: 0.3542 - val_precision: 0.0000e+00\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3778 - accuracy: 0.2604 - precision: 0.0000e+00\n",
      "Epoch 45: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 21s 7s/step - loss: 1.3778 - accuracy: 0.2604 - precision: 0.0000e+00 - val_loss: 1.4047 - val_accuracy: 0.2708 - val_precision: 0.0000e+00\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.4927 - accuracy: 0.3229 - precision: 0.3529\n",
      "Epoch 46: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 19s 7s/step - loss: 1.4927 - accuracy: 0.3229 - precision: 0.3529 - val_loss: 1.3860 - val_accuracy: 0.1771 - val_precision: 0.0000e+00\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3874 - accuracy: 0.2083 - precision: 0.0000e+00\n",
      "Epoch 47: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 21s 7s/step - loss: 1.3874 - accuracy: 0.2083 - precision: 0.0000e+00 - val_loss: 1.3852 - val_accuracy: 0.3021 - val_precision: 0.0000e+00\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3877 - accuracy: 0.2708 - precision: 0.0000e+00\n",
      "Epoch 48: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 19s 7s/step - loss: 1.3877 - accuracy: 0.2708 - precision: 0.0000e+00 - val_loss: 1.3845 - val_accuracy: 0.1146 - val_precision: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3839 - accuracy: 0.2917 - precision: 0.0000e+00\n",
      "Epoch 49: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 20s 7s/step - loss: 1.3839 - accuracy: 0.2917 - precision: 0.0000e+00 - val_loss: 1.3877 - val_accuracy: 0.2604 - val_precision: 0.0000e+00\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3861 - accuracy: 0.2500 - precision: 0.0000e+00\n",
      "Epoch 50: accuracy did not improve from 0.34375\n",
      "3/3 [==============================] - 21s 7s/step - loss: 1.3861 - accuracy: 0.2500 - precision: 0.0000e+00 - val_loss: 1.3888 - val_accuracy: 0.2396 - val_precision: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "#### Fitting the model\n",
    "history = model.fit(\n",
    "           train_data, steps_per_epoch=train_data.samples // batch_size, \n",
    "           epochs=epochs, \n",
    "           validation_data=test_data,validation_steps=test_data.samples // batch_size,\n",
    "           callbacks=[M])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020a8c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8039ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(history.history['accuracy'])\n",
    "\n",
    "for i in range(epochs):\n",
    "    if i%5 == 0:\n",
    "        plt.annotate(np.round(history.history['accuracy'][i]*100,2),xy=(i,history.history['accuracy'][i]))\n",
    "\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f76ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "for i in range(epochs):\n",
    "    if i%5 == 0:\n",
    "        plt.annotate(np.round(history.history['loss'][i]*100,2),xy=(i,history.history['loss'][i]))\n",
    "\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
